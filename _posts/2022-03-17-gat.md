---
layout: post
title: 'GAT'
date: 2022-03-17
author: downeyking
cover: 'https://gitee.com/GoPrime/imagecloud/raw/master/img/image-20220317221524335.png'
tags:DL

---

> 图注意力网络

## 前言

### 1 图前置知识

一般我们在图进行特征抽取时，关注的通常为图的两大性质：图的拓扑结构（以邻接矩阵的方式给出），图节点信息（节点本身的性质）。图深度学习通常便是对这两大性质进行有效的归纳与结合，其中一种常见的形式为**消息传递范式**。

**消息传递范式是一种聚合邻接节点信息来更新中心节点信息的范式**，它将卷积算子推广到了不规则数据领域，实现了图与神经网络的连接。**该范式包含这样三个步骤：(1)邻接节点信息变换、(2)邻接节点信息聚合到中心节点、(3)聚合信息变换**。

而本文将要介绍的[GAT(Graph Attention Netword)](https://arxiv.org/abs/1710.10903)，也遵循消息传递范式规律，其将注意力机制引入到图上，在更新节点A的特征向量时，先计算出所有邻居的注意力分数，再用这个注意力分数乘以对应邻居的特征，之后加在一起，就是节点A更新后的特征。接下来我们将会借助公式来理解节点特征更新过程。

### **2 GAT 节点特征更新过程**

给定N个节点特征 $\mathbf{h}=\left\{\vec{h}_{1}, \vec{h}_{2}, \ldots, \vec{h}_{N}\right\}, \vec{h}_{i} \in \mathbb{R}^{F}$，其中每个节点特征维度为 $F$

**2.1 计算注意力系数**

$e_{ij} = \left(\overrightarrow{\mathbf{a}}^{T}\left[\mathbf{W} \vec{h}_{i} \| \mathbf{W} \vec{h}_{j}\right]\right)$

- $e_{ij}$ ：表示节点 $j$ 相对于节点 $i$ 的注意力值。
- $\overrightarrow{\mathbf{a}}^{T}$ 和  $W$：共享的可学习参数。

解读：**首先将节点特征通过共享参数 $W$ 进行维度扩展，之后利用concat操作将节点 $i$ 和节点 $j$ 经过参数变换后的特征进行拼接；最后利用attentional mechanism $a(*)$将拼接后高维特征映射为实数 **

**2.2 注意力系数归一化**

要注意一点，$a_{ij}$不等于$a_{ji}$，所以我们生成的注意力分数矩阵应该是 $N*N$ 大小的

$\alpha_{i j}=\operatorname{softmax}_{j}\left(e_{i j}\right)=\frac{\exp \left(e_{i j}\right)}{\sum_{k \in \mathcal{N}_{i}} \exp \left(e_{i k}\right)} = \frac{\exp \left(\operatorname{LeakyReLU}\left(\overrightarrow{\mathbf{a}}^{T}\left[\mathbf{W} \vec{h}_{i} \| \mathbf{W} \vec{h}_{j}\right]\right)\right)}{\sum_{k \in \mathcal{N}_{i}} \exp \left(\operatorname{LeakyReLU}\left(\overrightarrow{\mathbf{a}}^{T}\left[\mathbf{W} \vec{h}_{i} \| \mathbf{W} \vec{h}_{k}\right]\right)\right)}$ 

即通过softmax对注意力系数进行归一化：

<img src="https://gitee.com/GoPrime/imagecloud/raw/master/img/image-20220317221541988.png" alt="image-20220317221541988" style="zoom:67%;" />

**2.3 节点特征更新**

$\vec{h}_{i}^{\prime}=\sigma\left(\sum_{j \in \mathcal{N}_{i}} \alpha_{i j} \mathbf{W} \vec{h}_{j}\right)$

- $\vec{h}_{i}^{\prime}$ ：节点 $i$ 在融合了邻域信息后的新特征（注意这一步通过注意力系数已经包含了自身前一层的特征信息。
- $\sigma$ ：激活函数。
- $W$ ：与前面的维度扩展参数 $W$ 相同。

通过这一步后我们已经完成了消息传递范式的三部曲，成功将邻域的信息融合并更新节点特征。

原文中提到：

> To stabilize the learning process of self-attention, we have found extending our mechanism to employ multi-head attention to be beneficial, similarly to Vaswani et al. (2017). 

在节点特征初步更新后，文章中还引入了[transformer](https://arxiv.org/abs/1706.03762)中提到的多头注意力机制来稳定自注意力的学习过程，即：

$\vec{h}_{i}^{\prime}=\|_{k=1}^{K} \sigma\left(\sum_{j \in \mathcal{N}_{i}} \alpha_{i j}^{k} \mathbf{W}^{k} \vec{h}_{j}\right)$

将每个头得到的节点特征进行concat，之后再average得到的节点特征，生成最终的节点特征：

$\vec{h}_{i}^{\prime}=\sigma\left(\frac{1}{K} \sum_{k=1}^{K} \sum_{j \in \mathcal{N}_{i}} \alpha_{i j}^{k} \mathbf{W}^{k} \vec{h}_{j}\right)$

详细过程参考下图：

<img src="https://gitee.com/GoPrime/imagecloud/raw/master/img/image-20220317221524335.png" alt="image-20220317221524335" style="zoom:67%;" />

### **3 pytorch代码实现**

数据集：cora数据集，共含有7类节点。每一个节点有1433个特征，一共有2708个节点，构成一个大图，属于分类任务。

代码见 [github](https://github.com/downeykking/graph)

实现了使用pyg框架的gat和底层gat。

实验结果：

| model         | GCN     | GAT       |
| :------------ | ------- | --------- |
| epoch         | 200     | 5000      |
| learning rate | 0.01    | 0.005     |
| dropout       | 0.5     | 0.6       |
| weight decay  | 5e-4    | 5e-4      |
| hidden        | 16      | 8         |
| seed          | 2022    | 2022      |
| head          | /       | 8         |
| alpha         | /       | 0.2       |
| epoch time    | 0.0031s | 0.0198s   |
| total time    | 0.6171s | 199.6522s |
| loss          | 0.4107  | 0.5054    |
| test acc      | 82.60   | 84.40     |

### **4 参考链接**

https://github.com/Diego999/pyGAT

https://blog.csdn.net/weixin_44517742/article/details/109081902

https://zhuanlan.zhihu.com/p/412270208

https://zhuanlan.zhihu.com/p/81350196

https://www.zhihu.com/question/338051122/answer/2282566492